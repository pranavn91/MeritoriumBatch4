{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-WeatherTweets_Textclassification.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Text Classification Workflow\n",
        "\n",
        "Hereâ€™s a high-level overview of the workflow used to solve machine learning problems:\n",
        "\n",
        "*   Step 1: Gather Data\n",
        "*   Step 2.5: Choose a Model*\n",
        "*   Step 3: Prepare Your Data\n",
        "*   Step 4: Build, Train, and Evaluate Your Model\n",
        "*   Step 5: Tune Hyperparameters\n",
        "*   Step 6: Deploy Your Model"
      ],
      "metadata": {
        "id": "nUqTMd7eesYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "i9MlJY8Mh0Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ryZKsvFeaMD"
      },
      "outputs": [],
      "source": [
        "def _load_and_shuffle_data(data_path,\n",
        "                           file_name,\n",
        "                           cols,\n",
        "                           seed,\n",
        "                           separator=',',\n",
        "                           header=0):\n",
        "    \"\"\"Loads and shuffles the dataset using pandas.\n",
        "    # Arguments\n",
        "        data_path: string, path to the data directory.\n",
        "        file_name: string, name of the data file.\n",
        "        cols: list, columns to load from the data file.\n",
        "        seed: int, seed for randomizer.\n",
        "        separator: string, separator to use for splitting data.\n",
        "        header: int, row to use as data header.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    data_path = os.path.join(data_path, file_name)\n",
        "    data = pd.read_csv(data_path, usecols=cols, sep=separator, header=header)\n",
        "    return data.reindex(np.random.permutation(data.index))\n",
        "\n",
        "\n",
        "def _split_training_and_validation_sets(texts, labels, validation_split):\n",
        "    \"\"\"Splits the texts and labels into training and validation sets.\n",
        "    # Arguments\n",
        "        texts: list, text data.\n",
        "        labels: list, label data.\n",
        "        validation_split: float, percentage of data to use for validation.\n",
        "    # Returns\n",
        "        A tuple of training and validation data.\n",
        "    \"\"\"\n",
        "    num_training_samples = int((1 - validation_split) * len(texts))\n",
        "    return ((texts[:num_training_samples], labels[:num_training_samples]),\n",
        "            (texts[num_training_samples:], labels[num_training_samples:]))\n",
        "    \n",
        "def load_tweet_weather_topic_classification_dataset(data_path,\n",
        "                                                    validation_split=0.2,\n",
        "                                                    seed=123):\n",
        "   \n",
        "    columns = [1] + [i for i in range(13, 28)]  # 1 - text, 13-28 - topics.\n",
        "    data = _load_and_shuffle_data(data_path, 'train.csv', columns, seed)\n",
        "\n",
        "    # Get tweet text and the max confidence score for the weather types.\n",
        "    texts = list(data['tweet'])\n",
        "    weather_data = data.iloc[:, 1:]\n",
        "\n",
        "    labels = []\n",
        "    for i in range(len(texts)):\n",
        "        # Pick topic with the max confidence score.\n",
        "        labels.append(np.argmax(list(weather_data.iloc[i, :].values)))\n",
        "\n",
        "    return _split_training_and_validation_sets(\n",
        "        texts, np.array(labels), validation_split)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, train_labels),(test_data, test_labels)=load_tweet_weather_topic_classification_dataset('')"
      ],
      "metadata": {
        "id": "Nl8ISMfQC-rV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}